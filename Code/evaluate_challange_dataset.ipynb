{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1575fa6-032e-46f9-8752-ffaf426cbf48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from data_utils import *\n",
    "from feature_utils import *\n",
    "\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7397fd9-0dc2-4359-8aff-bc5caf50d535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = '../models/distilbert-base-uncased-finetuned-advanced-argument-classification'\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06d3a589-6d44-4a44-bcbd-87671f8d39fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "      <th>capability</th>\n",
       "      <th>test_type</th>\n",
       "      <th>broad_capability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>passive_voice_mrt_1</td>\n",
       "      <td>The dog was adopted by family .</td>\n",
       "      <td>['ARG1', 'ARG1', 'O', 'O', 'O', 'ARG0', 'O']</td>\n",
       "      <td>passive_voice</td>\n",
       "      <td>mft</td>\n",
       "      <td>argument_alternation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>passive_voice_mrt_2</td>\n",
       "      <td>All the cookies have been eaten by children .</td>\n",
       "      <td>['ARG1', 'ARG1', 'ARG1', 'O', 'O', 'O', 'O', '...</td>\n",
       "      <td>passive_voice</td>\n",
       "      <td>mft</td>\n",
       "      <td>argument_alternation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passive_voice_mrt_3</td>\n",
       "      <td>A novel was being written by the author .</td>\n",
       "      <td>['ARG1', 'ARG1', 'O', 'O', 'O', 'O', 'ARG0', '...</td>\n",
       "      <td>passive_voice</td>\n",
       "      <td>mft</td>\n",
       "      <td>argument_alternation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passive_voice_mrt_4</td>\n",
       "      <td>The song was sung by the choir with great emot...</td>\n",
       "      <td>['ARG1', 'ARG1', 'O', 'O', 'O', 'ARG0', 'ARG0'...</td>\n",
       "      <td>passive_voice</td>\n",
       "      <td>mft</td>\n",
       "      <td>argument_alternation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passive_voice_mrt_5</td>\n",
       "      <td>The project was completed by the group ahead o...</td>\n",
       "      <td>['ARG1', 'ARG1', 'O', 'O', 'O', 'ARG0', 'ARG0'...</td>\n",
       "      <td>passive_voice</td>\n",
       "      <td>mft</td>\n",
       "      <td>argument_alternation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                           sentence  \\\n",
       "0  passive_voice_mrt_1                    The dog was adopted by family .   \n",
       "1  passive_voice_mrt_2      All the cookies have been eaten by children .   \n",
       "2  passive_voice_mrt_3          A novel was being written by the author .   \n",
       "3  passive_voice_mrt_4  The song was sung by the choir with great emot...   \n",
       "4  passive_voice_mrt_5  The project was completed by the group ahead o...   \n",
       "\n",
       "                                              labels     capability test_type  \\\n",
       "0       ['ARG1', 'ARG1', 'O', 'O', 'O', 'ARG0', 'O']  passive_voice       mft   \n",
       "1  ['ARG1', 'ARG1', 'ARG1', 'O', 'O', 'O', 'O', '...  passive_voice       mft   \n",
       "2  ['ARG1', 'ARG1', 'O', 'O', 'O', 'O', 'ARG0', '...  passive_voice       mft   \n",
       "3  ['ARG1', 'ARG1', 'O', 'O', 'O', 'ARG0', 'ARG0'...  passive_voice       mft   \n",
       "4  ['ARG1', 'ARG1', 'O', 'O', 'O', 'ARG0', 'ARG0'...  passive_voice       mft   \n",
       "\n",
       "        broad_capability  \n",
       "0  argument_alternation   \n",
       "1  argument_alternation   \n",
       "2  argument_alternation   \n",
       "3  argument_alternation   \n",
       "4  argument_alternation   "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challange_mft_df = pd.read_csv('../Data/challangedataset_mft.csv', encoding='utf-8')\n",
    "challange_mft_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c093cd6-9c38-43e2-bb27-7b574b5dd21c",
   "metadata": {},
   "source": [
    "Argument labels mapping to IDs from training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72d679d4-c686-4be6-ad21-79cc7ffe0bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_mapping = {'ARGM-MOD': 0,\n",
    " 'ARGM-ADJ': 1,\n",
    " 'ARG1-DSP': 2,\n",
    " 'O': 3,\n",
    " 'ARGA': 4,\n",
    " 'ARGM-DIS': 5,\n",
    " 'ARGM-COM': 6,\n",
    " 'ARGM-CXN': 7,\n",
    " 'ARGM-ADV': 8,\n",
    " 'ARGM-CAU': 9,\n",
    " 'ARGM-LOC': 10,\n",
    " 'ARGM-NEG': 11,\n",
    " 'ARGM-PRP': 12,\n",
    " 'ARGM-REC': 13,\n",
    " 'ARGM-DIR': 14,\n",
    " 'ARG0': 15,\n",
    " 'ARG3': 16,\n",
    " 'ARGM-GOL': 17,\n",
    " 'ARG5': 18,\n",
    " 'ARG4': 19,\n",
    " 'ARGM-EXT': 20,\n",
    " 'ARGM-PRD': 21,\n",
    " 'ARGM-PRR': 22,\n",
    " 'ARGM-LVB': 23,\n",
    " 'ARGM-MNR': 24,\n",
    " 'ARG1': 25,\n",
    " 'ARGM-TMP': 26,\n",
    " 'ARG2': 27}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dc831b4-fd4d-4ca7-8c0d-0dcc97129ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_mft_data(data):\n",
    "    \"\"\"\n",
    "    Prepares mft dataset for predictions.\n",
    "    \n",
    "    params:\n",
    "    data: DataFrame of mft challange dataset.\n",
    "    \"\"\"\n",
    "    # string split for sentence\n",
    "    data['sentence'] = data['sentence'].apply(lambda x: x.split())\n",
    "    # convert labels to string format\n",
    "    data['labels'] = data['labels'].apply(ast.literal_eval)\n",
    "    # map labels to integers corresponding to those in training\n",
    "    data['labels_mapped'] = data['labels'].apply(lambda x: [labels_mapping[label] for label in x])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7822209d-70a6-435d-8dc6-90cb5d822086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mft_df = process_mft_data(challange_mft_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c9f73b1-2868-4646-8d09-cb43e919c2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "      <th>capability</th>\n",
       "      <th>test_type</th>\n",
       "      <th>broad_capability</th>\n",
       "      <th>labels_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>passive_voice_mrt_1</td>\n",
       "      <td>[The, dog, was, adopted, by, family, .]</td>\n",
       "      <td>[ARG1, ARG1, O, O, O, ARG0, O]</td>\n",
       "      <td>passive_voice</td>\n",
       "      <td>mft</td>\n",
       "      <td>argument_alternation</td>\n",
       "      <td>[25, 25, 3, 3, 3, 15, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>passive_voice_mrt_2</td>\n",
       "      <td>[All, the, cookies, have, been, eaten, by, chi...</td>\n",
       "      <td>[ARG1, ARG1, ARG1, O, O, O, O, ARG0, O]</td>\n",
       "      <td>passive_voice</td>\n",
       "      <td>mft</td>\n",
       "      <td>argument_alternation</td>\n",
       "      <td>[25, 25, 25, 3, 3, 3, 3, 15, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passive_voice_mrt_3</td>\n",
       "      <td>[A, novel, was, being, written, by, the, autho...</td>\n",
       "      <td>[ARG1, ARG1, O, O, O, O, ARG0, ARG0, O]</td>\n",
       "      <td>passive_voice</td>\n",
       "      <td>mft</td>\n",
       "      <td>argument_alternation</td>\n",
       "      <td>[25, 25, 3, 3, 3, 3, 15, 15, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passive_voice_mrt_4</td>\n",
       "      <td>[The, song, was, sung, by, the, choir, with, g...</td>\n",
       "      <td>[ARG1, ARG1, O, O, O, ARG0, ARG0, O, O, O, O]</td>\n",
       "      <td>passive_voice</td>\n",
       "      <td>mft</td>\n",
       "      <td>argument_alternation</td>\n",
       "      <td>[25, 25, 3, 3, 3, 15, 15, 3, 3, 3, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passive_voice_mrt_5</td>\n",
       "      <td>[The, project, was, completed, by, the, group,...</td>\n",
       "      <td>[ARG1, ARG1, O, O, O, ARG0, ARG0, O, O, O, O]</td>\n",
       "      <td>passive_voice</td>\n",
       "      <td>mft</td>\n",
       "      <td>argument_alternation</td>\n",
       "      <td>[25, 25, 3, 3, 3, 15, 15, 3, 3, 3, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                           sentence  \\\n",
       "0  passive_voice_mrt_1            [The, dog, was, adopted, by, family, .]   \n",
       "1  passive_voice_mrt_2  [All, the, cookies, have, been, eaten, by, chi...   \n",
       "2  passive_voice_mrt_3  [A, novel, was, being, written, by, the, autho...   \n",
       "3  passive_voice_mrt_4  [The, song, was, sung, by, the, choir, with, g...   \n",
       "4  passive_voice_mrt_5  [The, project, was, completed, by, the, group,...   \n",
       "\n",
       "                                          labels     capability test_type  \\\n",
       "0                 [ARG1, ARG1, O, O, O, ARG0, O]  passive_voice       mft   \n",
       "1        [ARG1, ARG1, ARG1, O, O, O, O, ARG0, O]  passive_voice       mft   \n",
       "2        [ARG1, ARG1, O, O, O, O, ARG0, ARG0, O]  passive_voice       mft   \n",
       "3  [ARG1, ARG1, O, O, O, ARG0, ARG0, O, O, O, O]  passive_voice       mft   \n",
       "4  [ARG1, ARG1, O, O, O, ARG0, ARG0, O, O, O, O]  passive_voice       mft   \n",
       "\n",
       "        broad_capability                          labels_mapped  \n",
       "0  argument_alternation                [25, 25, 3, 3, 3, 15, 3]  \n",
       "1  argument_alternation         [25, 25, 25, 3, 3, 3, 3, 15, 3]  \n",
       "2  argument_alternation         [25, 25, 3, 3, 3, 3, 15, 15, 3]  \n",
       "3  argument_alternation   [25, 25, 3, 3, 3, 15, 15, 3, 3, 3, 3]  \n",
       "4  argument_alternation   [25, 25, 3, 3, 3, 15, 15, 3, 3, 3, 3]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mft_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3eef9481-0cbf-46ee-9f4b-d6e9b3fec2e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(data):\n",
    "    \"\"\"\n",
    "    Tokenizes the input examples and aligns argument labels and ids.\n",
    "\n",
    "    Parameters:\n",
    "    data: DataFrame containing tokens, sentence IDs, and argument labels/ids.\n",
    "    multilabel: True for argument classifcation else argument identification (binary).\n",
    "    label_all_tokens: bool for labeling all tokens.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of new examples with tokenized inputs and aligned labels.\n",
    "    \"\"\"\n",
    "    sentence_lists = data['sentence'].tolist()\n",
    "    sentence_ids = data['ID'].tolist()\n",
    "\n",
    "    # Tokenize sentences:\n",
    "    tokenized_inputs = tokenizer(sentence_lists, truncation=True, is_split_into_words=True)\n",
    "\n",
    "    aligned_examples = []\n",
    "\n",
    "    for i,  arg_label in enumerate(data['labels_mapped']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        arg_ids = []\n",
    "        labels = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None: # set arg id and label to -100 for first and last special tokens\n",
    "                arg_ids.append(-100)\n",
    "                labels.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                labels.append(arg_label[word_idx])\n",
    "            else:\n",
    "                labels.append(arg_label[word_idx])\n",
    "\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        \n",
    "        aligned_examples.append({\n",
    "            'sentence_id': sentence_ids[i],\n",
    "            'sentence': sentence_lists[i],\n",
    "            'word_ids': word_ids,\n",
    "            'input_ids': tokenized_inputs['input_ids'][i],\n",
    "            'attention_mask': tokenized_inputs['attention_mask'][i],\n",
    "            'labels': labels,\n",
    "        })\n",
    "        \n",
    "\n",
    "    return aligned_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5e23e75-5be6-4f48-9e01-b6154a7bdbe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_examples_mft = tokenize_and_align_labels(mft_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd2d8857-8576-4e56-9b3d-e0566fd430d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'project',\n",
       " 'was',\n",
       " 'completed',\n",
       " 'by',\n",
       " 'the',\n",
       " 'group',\n",
       " 'ahead',\n",
       " 'of',\n",
       " 'schedule',\n",
       " '.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_examples_mft[4]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e041c67d-e496-4884-84b2-2455c0d889ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100, 25, 25, 3, 3, 3, 15, 15, 3, 3, 3, 3, -100]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_examples_mft[4]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "140ed842-064c-4b05-b20c-cf4c6e3490b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 7, 7],\n",
       "        [7, 7, 7],\n",
       "        [7, 7, 7],\n",
       "        [7, 7, 7],\n",
       "        [7, 7, 7],\n",
       "        [7, 7, 7],\n",
       "        [7, 7, 7]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(tokenized_examples_mft[15]['sentence'], return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "predictions = outputs.logits.argmax(dim=2)\n",
    "#predictions = [id2label[prediction] for prediction in predictions[0].tolist()]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8124c3f9-c8bc-4ce0-8554-e3e60b71d0de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_examples_mft[4]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb9d7c53-6b94-4082-9195-19db20d4dc48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2b30eef-39f9-4ac6-a4eb-14aace0ff4a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "\n",
    "example = tokenized_examples_mft[0]\n",
    "input_ids = torch.tensor(example['input_ids']).unsqueeze(0)\n",
    "attention_mask = torch.tensor(example['attention_mask']).unsqueeze(0)\n",
    "outputs = model(input_ids, attention_mask=attention_mask)\n",
    "logits = outputs.logits\n",
    "aggregated_logits = aggregate_subtoken_logits([example], logits.detach().numpy())[0]\n",
    "aggregated_predictions = np.argmax(aggregated_logits, axis=1)\n",
    "#pred_labels = [id2label[label_id] for label_id in aggregated_predictions]\n",
    "#predicted_labels.append(pred_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71dd480b-2d0c-482f-a4c8-eabeeccc3c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_examples_mft[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76c5b094-ec5c-4d08-b5a4-2f4b473f764e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 16, 16, 16, 16, 16, 16])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2df98f1-ff40-4000-8fb0-e11d0a9e8d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence_id': 'passive_voice_mrt_1',\n",
       " 'sentence': ['The', 'dog', 'was', 'adopted', 'by', 'family', '.'],\n",
       " 'word_ids': [None, 0, 1, 2, 3, 4, 5, 6, None],\n",
       " 'input_ids': [101, 1996, 3899, 2001, 4233, 2011, 2155, 1012, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [-100, 25, 25, 3, 3, 3, 15, 3, -100]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_examples_mft[0]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m117"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
